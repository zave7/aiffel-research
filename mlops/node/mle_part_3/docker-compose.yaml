version: "3"

services:
  api-with-model:
    build: 
      context: .
      dockerfile: Dockerfile
    container_name: api-with-model
    ports:
      - 8000:8000
    healthcheck:
      test:
        - CMD
        - curl -X POST http://localhost:8000/predict
        - -H
        - "Content-Type: application/json"
        - -d
        - '{"sepal_length": 6.7, "sepal_width": 3.3, "petal_length": 5.7, "petal_width": 2.1}'
      interval: 7s
      timeout: 5s
      retries: 5
      # start_period: 30s
  front-app:
    build: 
      context: .
      dockerfile: Dockerfile_streamlit
    container_name: front-app
    ports:
      - 8501:8501
    command: ["--", "--infer-host", "http://api-with-model:8000/predict"]
networks:
  default:
    name: mlops-network
    external: true